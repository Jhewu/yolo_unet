{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Current Problem\n",
        "- Model predicts low losses with (e.g., DICE loss), but when using it to predict on either testing or training datasets, the output is a mask that's all zero "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3eE_EEND7k2D"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mKERAS_BACKEND\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtensorflow\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" \n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "from keras import layers\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1741217510.874714  153400 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13140 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Limiting GPU memory growth\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    # keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "    # print(\"Using mixed_precision float16\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "image_dir = \"cleaned_t1c/images\"\n",
        "mask_dir = \"cleaned_t1c/masks\"\n",
        "image_size = (240, 240)\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "There is approximately 3095 images within the training set\n",
            "\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00064-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00064-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00065-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00065-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00066-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00066-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00067-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00067-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00068-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00068-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00069-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00069-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00070-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00070-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00071-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00071-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00072-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00072-t1c.png\n",
            "cleaned_t1c/images/train/BraTS-PED-00002-00073-t1c.png | cleaned_t1c/masks/train/BraTS-PED-00002-00073-t1c.png\n"
          ]
        }
      ],
      "source": [
        "# Create lists of images for each partition\n",
        "\n",
        "def sort_list(image_dir): \n",
        "    # Create function that will sort the partition list\n",
        "    return sorted(\n",
        "        [\n",
        "            os.path.join(image_dir, fname)\n",
        "            for fname in os.listdir(image_dir)\n",
        "            if fname.endswith(\".png\")\n",
        "        ]\n",
        "        )\n",
        "\n",
        "# Create the sorted list for the images partition\n",
        "train_image = sort_list(os.path.join(image_dir, \"train\"))\n",
        "val_image = sort_list(os.path.join(image_dir, \"val\"))\n",
        "test_image = sort_list(os.path.join(image_dir, \"test\"))\n",
        "\n",
        "# Create the sorted list for the masks partition\n",
        "train_mask = sort_list(os.path.join(mask_dir, \"train\"))\n",
        "val_mask = sort_list(os.path.join(mask_dir, \"val\"))\n",
        "test_mask = sort_list(os.path.join(mask_dir, \"test\"))\n",
        "\n",
        "print(f\"\\nThere is approximately {len(train_image)} images within the training set\\n\")\n",
        "\n",
        "for input_path, target_path in zip(train_image[:10], train_mask[:10]):\n",
        "    print(input_path, \"|\", target_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/jpeg": "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",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAIAAACxN37FAAAFYklEQVR4Ae3d0W6cMBAF0KTK//9yihTFQsBmF3vMGO/JSxGLx+PjW4eokfrx4YsAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQK5Ap+505u9CHx/f5fr5eLz09asPV69/nr1Qc+NJLBJ/7q1N/+b4BhYhyHt+jCg+2gePnbY9H7s4WPz3RToUfZ0E9ZNIjefvt70ps7rA2/6pEAPsXGHeS1ZPPz0VN+l1KlRd3z43x2bnq/nfeD2d1pW3f5XomX2K8cK9JXaNXO9TxZrdHZjvHLsSFJvLPHdnM09Ar2ZInXFwZMLdDBoeLkegS5NzpdsgS6bO+JF1zSvFzxNsgV6va1jXV+W5rLsCWLth8Kym2NdXJ/mZf0pk8a6C3Ssp2rJAgKdvAGH0yeelIlTH1KcvSnQZ8U8P7SAQA+3PelnZHoDLVsi0C168WNvHaZ4jvMVBfq8mREDCwj0QJvjeG7fDIFuN1RhIAGBHmgztNIuINDthmEVBvmX50HaqGMV6Dq3plHelZv4/hzsl5P+5In+cBPlw7Nw80x0C8/rHXb1fNgYTzihx9iH3y6k+Vei8k+BroSrGLYP6/5ORVlD1gICvdboe73/Vr6/07eDZ9VH6+dZvwefC/QBilv3FfBDYcLeLW8aj87CxJeQRy0lADVM6YRuwKsdOkd0alffd5xA9/VV/WIBgb4YfNDppvmmIdCDJiy3rcRX+caFC3Qj4AzDN8fzfdO8bIZAz5DIljXMlGaBbklC/Nj0ozG9gXZT/yVFu+GNK5TjeRPlcv92a/PKcbstC2v4UWof3Q+buGchJ3RP3fvUvnWI18xO6LXGe11vXjPmWLxAz7GPMauYIOICHROFkCqJ3/eXKC9fiQ2EAC5F/LZdlGRMnSVVMYXOV5kgzcuiBfr8zncecX2m54jyz7YIdOd41pa/INYz5bgwC3ShGP0iPOJTBtoPhaPnuPQXm7/YaqXJ9AuBTt+ChAZmTfNCKdAJeaqeMiSIIUWql9B7oHfo3sJd6le/T8+d5sVaoLsE7sqir4d7+jQv7F45rsxe5lzvkObF1wmdGbKouf8+pN8kyj+YAh0Vqvw6+1i/VZTzN0AHBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBOYT+A+cSpNkdnLIiwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=240x240>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([240 240   1], shape=(3,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[0.         0.18431373 0.21960784 0.17254902 0.16078432 0.14117648\n",
            " 0.18039216 0.23921569 0.24313726 0.27450982 0.25882354 0.2901961\n",
            " 0.34901962 0.2784314  0.23137255 0.16470589 0.12941177 0.12156863\n",
            " 0.21176471 0.28627452 0.33333334 0.3529412  0.39607844 0.43137255\n",
            " 0.41960785 0.43529412 0.44705883 0.4117647  0.37254903 0.3647059\n",
            " 0.36862746 0.38431373 0.41568628 0.40392157 0.42745098 0.54509807\n",
            " 0.47843137 0.34509805 0.5647059  0.4392157  0.2627451  0.26666668\n",
            " 0.1882353  0.27058825 0.3137255  0.34117648 0.35686275 0.36078432\n",
            " 0.32941177 0.29411766 0.30588236 0.39215687 0.38039216 0.45882353\n",
            " 0.4627451  0.47058824 0.7058824  0.8        0.6666667  0.3882353\n",
            " 0.14901961 0.05098039 0.20392157 0.23529412 0.28235295 0.29803923\n",
            " 0.30980393 0.3372549  0.32156864 0.3764706  0.4509804  0.64705884\n",
            " 0.6509804  0.3254902  0.07058824 0.21568628 0.2509804  0.3019608\n",
            " 0.44313726 0.48235294 0.49803922 0.5058824  0.49411765 0.46666667\n",
            " 0.4        0.40784314 0.07843138 0.31764707 0.5254902  0.67058825\n",
            " 0.49019608 0.20784314 0.13333334 0.63529414 0.45490196 0.22352941\n",
            " 0.5411765  0.654902   0.4745098  0.16862746 0.15294118 0.5137255\n",
            " 0.60784316 0.5176471  0.6039216  0.42352942 0.14509805 0.5372549\n",
            " 0.5019608  0.50980395 0.5882353  0.25490198 0.5803922  0.53333336\n",
            " 0.5294118  0.19215687 0.24705882 0.13725491 0.4862745  0.54901963\n",
            " 0.1254902  0.58431375 0.62352943 0.6627451  0.7019608  0.10980392\n",
            " 0.57254905 0.6        0.5921569  0.2        0.10588235 0.52156866\n",
            " 0.5568628  0.5686275  0.6901961  0.6117647  0.5529412  0.6156863\n",
            " 0.5764706  0.6745098  0.09803922 0.59607846 0.6392157  0.56078434\n",
            " 0.65882355 0.6313726  0.61960787 0.07450981 0.6431373  0.627451\n",
            " 0.05882353 0.08235294 0.69411767 0.15686275 0.08627451 0.05490196\n",
            " 0.06666667 0.1764706  0.19607843 0.09411765 0.22745098 0.7529412\n",
            " 0.7137255  1.         0.6784314  0.8117647  0.7411765  0.76862746\n",
            " 0.827451   0.6862745  0.7764706  0.11764706 0.68235296 0.02745098\n",
            " 0.8039216  0.77254903 0.7647059  0.84705883 0.78431374 0.09019608\n",
            " 0.11372549 0.0627451 ], shape=(182,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Display the image to ensure it works correctly\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from keras.utils import load_img\n",
        "from PIL import ImageOps\n",
        "\n",
        "# Display input image #7\n",
        "display(Image(filename=train_image[100]))\n",
        "\n",
        "# Display auto-contrast version of corresponding target (per-pixel categories)\n",
        "img = ImageOps.autocontrast(load_img(train_mask[100]))\n",
        "\n",
        "display(img)\n",
        "\n",
        "# img = cv.imread(train_image[100])\n",
        "# mask = cv.imread(train_mask[100])\n",
        "# print(np.unique(mask))\n",
        "# print(np.unique(img))\n",
        "\n",
        "# input_img = tf_io.read_file(train_image[100])\n",
        "# input_img = tf_io.decode_png(input_img, channels=1)\n",
        "# input_img = tf_image.resize(input_img, image_size)\n",
        "# input_img = tf.cast(input_img, tf.float32) / 255.0\n",
        "\n",
        "# print(tf.shape(input_img))\n",
        "# print(tf.unique(tf.reshape(input_img, [-1])).y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BAHT78pP7k2E"
      },
      "outputs": [],
      "source": [
        "# Create the function that returns TF datasets by pairing the image and mask\n",
        "\n",
        "def get_dataset(\n",
        "    batch_size,\n",
        "    image_size,\n",
        "    image_paths,\n",
        "    mask_paths,):\n",
        "    \"\"\"Returns a TF Dataset.\"\"\"\n",
        "\n",
        "    def load_img_masks(input_img_path, target_img_path):\n",
        "        input_img = tf_io.read_file(input_img_path)\n",
        "        input_img = tf_io.decode_png(input_img, channels=1)\n",
        "        input_img = tf_image.resize(input_img, image_size)\n",
        "        input_img = tf.cast(input_img, tf.float32) / 255.0\n",
        "\n",
        "        target_img = tf_io.read_file(target_img_path)\n",
        "        target_img = tf_io.decode_png(target_img, channels=1)\n",
        "        target_img = tf_image.resize(target_img, image_size, method=\"nearest\")\n",
        "        target_img = tf.cast(target_img, tf.float32) / 255.0\n",
        "\n",
        "        return input_img, target_img\n",
        "\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
        "    dataset = dataset.map(load_img_masks, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "    return dataset.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,392</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,720</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,248</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">165,984</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │     \u001b[38;5;34m55,392\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │    \u001b[38;5;34m110,720\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │    \u001b[38;5;34m295,040\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │     \u001b[38;5;34m49,248\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │    \u001b[38;5;34m165,984\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m24,640\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m73,792\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_transpose_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │      \u001b[38;5;34m8,224\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │     \u001b[38;5;34m18,464\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │         \u001b[38;5;34m33\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,390,401</span> (9.12 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,390,401\u001b[0m (9.12 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,390,401</span> (9.12 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,390,401\u001b[0m (9.12 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def get_model(img_size, num_classes=1):\n",
        "    inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(96, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "model = get_model(image_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Uzg8A8u7k2F"
      },
      "outputs": [],
      "source": [
        "# # Define the function to create a unet\n",
        "\n",
        "# def get_model(img_size):\n",
        "#     inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "#     ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "#     # Entry block\n",
        "#     x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "#     previous_block_activation = x  # Set aside residual\n",
        "\n",
        "#     # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "#     for filters in [64, 128, 256]:\n",
        "#         x = layers.Activation(\"relu\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"relu\")(x)\n",
        "        \n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "#             previous_block_activation\n",
        "#         )\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "#     for filters in [256, 128, 64, 32]:\n",
        "#         x = layers.Activation(\"relu\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"relu\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "#         residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     # Add a per-pixel classification layer\n",
        "#     outputs = layers.Conv2D(1, 1, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "#     # Define the model\n",
        "#     model = keras.Model(inputs, outputs)\n",
        "#     return model\n",
        "\n",
        "\n",
        "# # Build model\n",
        "# model = get_model(image_size)\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-2YRfi4x7k2F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 240, 240, 1)\n",
            "(16, 240, 240, 1)\n",
            "[0.         0.10588235 0.10980392 0.11372549 0.11764706 0.12156863\n",
            " 0.1254902  0.12941177 0.13333334 0.13725491 0.14117648 0.14509805\n",
            " 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746\n",
            " 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687\n",
            " 0.19607843 0.2        0.20392157 0.20784314 0.21176471 0.21568628\n",
            " 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569\n",
            " 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451\n",
            " 0.26666668 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452\n",
            " 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236 0.30980393\n",
            " 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177 0.33333334\n",
            " 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412  0.35686275\n",
            " 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216\n",
            " 0.38431373 0.3882353  0.39215687 0.39607844 0.4        0.40392157\n",
            " 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098\n",
            " 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804\n",
            " 0.45490196 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098\n",
            " 0.47843137 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922\n",
            " 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471  0.52156866\n",
            " 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765  0.54509807\n",
            " 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275\n",
            " 0.57254905 0.5764706  0.5803922  0.58431375 0.5882353  0.59607846\n",
            " 0.6        0.6039216  0.60784316 0.6156863  0.61960787 0.62352943\n",
            " 0.627451   0.6313726  0.63529414 0.6392157  0.6431373  0.64705884\n",
            " 0.6509804  0.65882355 0.6627451  0.6666667  0.67058825 0.6745098\n",
            " 0.68235296 0.6862745  0.6901961  0.69803923 0.7176471  0.72156864\n",
            " 0.7254902  0.73333335 0.7372549  0.7607843  0.7921569  0.79607844\n",
            " 0.8        0.8392157  0.84705883 0.8862745  0.8901961  1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.10588235 0.10980392 0.11372549 0.11764706 0.12156863\n",
            " 0.1254902  0.12941177 0.13333334 0.13725491 0.14117648 0.14509805\n",
            " 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746\n",
            " 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687\n",
            " 0.19607843 0.2        0.20392157 0.20784314 0.21176471 0.21568628\n",
            " 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569\n",
            " 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451\n",
            " 0.26666668 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452\n",
            " 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236 0.30980393\n",
            " 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177 0.33333334\n",
            " 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412  0.35686275\n",
            " 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216\n",
            " 0.38431373 0.3882353  0.39215687 0.39607844 0.4        0.40392157\n",
            " 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098\n",
            " 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804\n",
            " 0.45490196 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098\n",
            " 0.47843137 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922\n",
            " 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471  0.52156866\n",
            " 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765  0.54509807\n",
            " 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275\n",
            " 0.57254905 0.5764706  0.5803922  0.58431375 0.5882353  0.5921569\n",
            " 0.59607846 0.6        0.60784316 0.6156863  0.61960787 0.62352943\n",
            " 0.627451   0.6313726  0.63529414 0.6392157  0.64705884 0.6509804\n",
            " 0.654902   0.65882355 0.6627451  0.6666667  0.67058825 0.6745098\n",
            " 0.6784314  0.68235296 0.69803923 0.7019608  0.70980394 0.7137255\n",
            " 0.72156864 0.7254902  0.7411765  0.76862746 0.77254903 0.7764706\n",
            " 0.7921569  0.8        0.8235294  0.8627451  0.87058824 0.9098039\n",
            " 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.08627451 0.09019608 0.09803922 0.10196079 0.10588235\n",
            " 0.10980392 0.11372549 0.11764706 0.12156863 0.1254902  0.12941177\n",
            " 0.13333334 0.13725491 0.14117648 0.14509805 0.14901961 0.15294118\n",
            " 0.15686275 0.16078432 0.16470589 0.16862746 0.17254902 0.1764706\n",
            " 0.18039216 0.18431373 0.1882353  0.19215687 0.19607843 0.2\n",
            " 0.20392157 0.20784314 0.21176471 0.21568628 0.21960784 0.22352941\n",
            " 0.22745098 0.23137255 0.23529412 0.23921569 0.24313726 0.24705882\n",
            " 0.2509804  0.25490198 0.25882354 0.2627451  0.26666668 0.27058825\n",
            " 0.27450982 0.2784314  0.28235295 0.28627452 0.2901961  0.29411766\n",
            " 0.29803923 0.3019608  0.30588236 0.30980393 0.3137255  0.31764707\n",
            " 0.32156864 0.3254902  0.32941177 0.33333334 0.3372549  0.34117648\n",
            " 0.34509805 0.34901962 0.3529412  0.35686275 0.36078432 0.3647059\n",
            " 0.36862746 0.37254903 0.3764706  0.38039216 0.38431373 0.3882353\n",
            " 0.39215687 0.39607844 0.4        0.40392157 0.40784314 0.4117647\n",
            " 0.41568628 0.41960785 0.42352942 0.42745098 0.43137255 0.43529412\n",
            " 0.4392157  0.44313726 0.44705883 0.4509804  0.45490196 0.45882353\n",
            " 0.4627451  0.46666667 0.47058824 0.4745098  0.47843137 0.48235294\n",
            " 0.4862745  0.49019608 0.49411765 0.49803922 0.5019608  0.50980395\n",
            " 0.5137255  0.5176471  0.52156866 0.5254902  0.5294118  0.53333336\n",
            " 0.5372549  0.5411765  0.54509807 0.54901963 0.5529412  0.5568628\n",
            " 0.56078434 0.5647059  0.5686275  0.57254905 0.5764706  0.5803922\n",
            " 0.58431375 0.5882353  0.5921569  0.59607846 0.6        0.6039216\n",
            " 0.6117647  0.6156863  0.61960787 0.62352943 0.627451   0.6313726\n",
            " 0.63529414 0.6392157  0.6431373  0.64705884 0.65882355 0.6627451\n",
            " 0.6666667  0.67058825 0.6745098  0.6862745  0.69803923 0.7058824\n",
            " 0.7294118  0.7372549  0.7411765  0.74509805 0.7529412  0.7607843\n",
            " 0.7647059  0.80784315 0.89411765 0.8980392  0.9019608  0.9254902\n",
            " 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.10196079 0.10588235 0.10980392 0.11372549 0.11764706\n",
            " 0.12156863 0.1254902  0.12941177 0.13333334 0.13725491 0.14117648\n",
            " 0.14509805 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589\n",
            " 0.16862746 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353\n",
            " 0.19215687 0.19607843 0.2        0.20392157 0.20784314 0.21176471\n",
            " 0.21568628 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412\n",
            " 0.23921569 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354\n",
            " 0.2627451  0.26666668 0.27058825 0.27450982 0.2784314  0.28235295\n",
            " 0.28627452 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236\n",
            " 0.30980393 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177\n",
            " 0.33333334 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412\n",
            " 0.35686275 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706\n",
            " 0.38039216 0.38431373 0.3882353  0.39215687 0.39607844 0.4\n",
            " 0.40392157 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942\n",
            " 0.42745098 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883\n",
            " 0.4509804  0.45490196 0.45882353 0.4627451  0.46666667 0.47058824\n",
            " 0.4745098  0.47843137 0.48235294 0.4862745  0.49019608 0.49411765\n",
            " 0.49803922 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471\n",
            " 0.52156866 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765\n",
            " 0.54509807 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059\n",
            " 0.5686275  0.57254905 0.5764706  0.5803922  0.58431375 0.5882353\n",
            " 0.5921569  0.59607846 0.6        0.6039216  0.60784316 0.6117647\n",
            " 0.61960787 0.62352943 0.627451   0.6313726  0.63529414 0.6392157\n",
            " 0.6431373  0.64705884 0.6509804  0.654902   0.65882355 0.6627451\n",
            " 0.6666667  0.67058825 0.6745098  0.6784314  0.6901961  0.69411767\n",
            " 0.7019608  0.7058824  0.70980394 0.7137255  0.72156864 0.7294118\n",
            " 0.7372549  0.7411765  0.74509805 0.7529412  0.75686276 0.7647059\n",
            " 0.76862746 0.77254903 0.7764706  0.8235294  0.83137256 0.8352941\n",
            " 0.8627451  0.8901961  0.8980392  1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.10980392 0.11372549 0.11764706 0.12156863 0.1254902\n",
            " 0.12941177 0.13333334 0.13725491 0.14117648 0.14509805 0.14901961\n",
            " 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746 0.17254902\n",
            " 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687 0.19607843\n",
            " 0.2        0.20392157 0.20784314 0.21176471 0.21568628 0.21960784\n",
            " 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569 0.24313726\n",
            " 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451  0.26666668\n",
            " 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452 0.2901961\n",
            " 0.29411766 0.29803923 0.3019608  0.30588236 0.30980393 0.3137255\n",
            " 0.31764707 0.32156864 0.3254902  0.32941177 0.33333334 0.3372549\n",
            " 0.34117648 0.34509805 0.34901962 0.3529412  0.35686275 0.36078432\n",
            " 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216 0.38431373\n",
            " 0.3882353  0.39215687 0.39607844 0.4        0.40392157 0.40784314\n",
            " 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098 0.43137255\n",
            " 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804  0.45490196\n",
            " 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098  0.47843137\n",
            " 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922 0.5019608\n",
            " 0.5058824  0.50980395 0.5137255  0.5176471  0.52156866 0.5254902\n",
            " 0.5294118  0.53333336 0.5372549  0.5411765  0.54509807 0.54901963\n",
            " 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275  0.57254905\n",
            " 0.5764706  0.5803922  0.58431375 0.5882353  0.5921569  0.59607846\n",
            " 0.6        0.6039216  0.60784316 0.6117647  0.61960787 0.62352943\n",
            " 0.627451   0.6313726  0.63529414 0.6392157  0.6431373  0.64705884\n",
            " 0.6509804  0.654902   0.6627451  0.6666667  0.67058825 0.6745098\n",
            " 0.6784314  0.68235296 0.6862745  0.6901961  0.69803923 0.7019608\n",
            " 0.7058824  0.70980394 0.7176471  0.72156864 0.7254902  0.7294118\n",
            " 0.73333335 0.7372549  0.7411765  0.74509805 0.7529412  0.7607843\n",
            " 0.7647059  0.77254903 0.7764706  0.78431374 0.7921569  0.79607844\n",
            " 0.80784315 0.8156863  0.827451   0.83137256 0.84313726 0.8509804\n",
            " 0.8627451  0.8745098  0.8784314  0.8862745  0.8901961  0.89411765\n",
            " 0.9019608  0.91764706 0.92156863 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.11764706 0.12156863 0.1254902  0.12941177 0.13333334\n",
            " 0.13725491 0.14117648 0.14509805 0.14901961 0.15294118 0.15686275\n",
            " 0.16078432 0.16470589 0.16862746 0.17254902 0.1764706  0.18039216\n",
            " 0.18431373 0.1882353  0.19215687 0.19607843 0.2        0.20392157\n",
            " 0.20784314 0.21176471 0.21568628 0.21960784 0.22352941 0.22745098\n",
            " 0.23137255 0.23529412 0.23921569 0.24313726 0.24705882 0.2509804\n",
            " 0.25490198 0.25882354 0.2627451  0.26666668 0.27058825 0.27450982\n",
            " 0.2784314  0.28235295 0.28627452 0.2901961  0.29411766 0.29803923\n",
            " 0.3019608  0.30588236 0.30980393 0.3137255  0.31764707 0.32156864\n",
            " 0.3254902  0.32941177 0.33333334 0.3372549  0.34117648 0.34509805\n",
            " 0.34901962 0.3529412  0.35686275 0.36078432 0.3647059  0.36862746\n",
            " 0.37254903 0.3764706  0.38039216 0.38431373 0.3882353  0.39215687\n",
            " 0.39607844 0.4        0.40392157 0.40784314 0.4117647  0.41568628\n",
            " 0.41960785 0.42352942 0.42745098 0.43137255 0.43529412 0.4392157\n",
            " 0.44313726 0.44705883 0.4509804  0.45490196 0.45882353 0.4627451\n",
            " 0.46666667 0.47058824 0.4745098  0.47843137 0.48235294 0.4862745\n",
            " 0.49019608 0.49411765 0.49803922 0.5019608  0.5058824  0.50980395\n",
            " 0.5137255  0.5176471  0.52156866 0.5254902  0.5294118  0.53333336\n",
            " 0.5372549  0.5411765  0.54509807 0.54901963 0.5529412  0.5568628\n",
            " 0.56078434 0.5647059  0.5686275  0.57254905 0.5764706  0.5803922\n",
            " 0.58431375 0.5882353  0.5921569  0.59607846 0.6        0.6039216\n",
            " 0.60784316 0.6117647  0.6156863  0.61960787 0.62352943 0.627451\n",
            " 0.6313726  0.63529414 0.6392157  0.6431373  0.64705884 0.6509804\n",
            " 0.654902   0.65882355 0.6627451  0.6666667  0.67058825 0.6745098\n",
            " 0.6784314  0.68235296 0.6862745  0.6901961  0.69411767 0.7019608\n",
            " 0.7058824  0.70980394 0.7137255  0.7176471  0.72156864 0.73333335\n",
            " 0.7372549  0.7411765  0.74509805 0.7529412  0.75686276 0.7607843\n",
            " 0.76862746 0.7764706  0.7882353  0.7921569  0.8        0.80784315\n",
            " 0.8117647  0.8156863  0.81960785 0.8352941  0.8392157  0.84705883\n",
            " 0.85490197 0.85882354 0.8666667  0.87058824 0.8745098  0.88235295\n",
            " 0.9019608  0.9137255  0.91764706 0.9254902  0.93333334 0.95686275\n",
            " 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.1254902  0.13333334 0.13725491 0.14117648 0.14509805\n",
            " 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746\n",
            " 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687\n",
            " 0.19607843 0.2        0.20392157 0.20784314 0.21176471 0.21568628\n",
            " 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569\n",
            " 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451\n",
            " 0.26666668 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452\n",
            " 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236 0.30980393\n",
            " 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177 0.33333334\n",
            " 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412  0.35686275\n",
            " 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216\n",
            " 0.38431373 0.3882353  0.39215687 0.39607844 0.4        0.40392157\n",
            " 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098\n",
            " 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804\n",
            " 0.45490196 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098\n",
            " 0.47843137 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922\n",
            " 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471  0.52156866\n",
            " 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765  0.54509807\n",
            " 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275\n",
            " 0.57254905 0.5764706  0.5803922  0.58431375 0.5882353  0.5921569\n",
            " 0.59607846 0.6        0.6039216  0.60784316 0.6117647  0.6156863\n",
            " 0.61960787 0.62352943 0.627451   0.6313726  0.63529414 0.6392157\n",
            " 0.6431373  0.64705884 0.6509804  0.654902   0.65882355 0.6627451\n",
            " 0.6666667  0.67058825 0.6745098  0.6784314  0.68235296 0.6862745\n",
            " 0.6901961  0.69411767 0.69803923 0.7058824  0.70980394 0.72156864\n",
            " 0.7372549  0.7490196  0.7529412  0.75686276 0.7607843  0.77254903\n",
            " 0.7764706  0.78431374 0.7882353  0.7921569  0.8039216  0.8117647\n",
            " 0.81960785 0.8235294  0.8352941  0.8392157  0.84313726 0.84705883\n",
            " 0.8509804  0.8666667  0.8784314  0.88235295 0.89411765 0.9137255\n",
            " 0.93333334 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.11764706 0.12156863 0.1254902  0.12941177 0.13333334\n",
            " 0.13725491 0.14117648 0.14509805 0.14901961 0.15294118 0.15686275\n",
            " 0.16078432 0.16470589 0.16862746 0.17254902 0.1764706  0.18039216\n",
            " 0.18431373 0.1882353  0.19215687 0.19607843 0.2        0.20392157\n",
            " 0.20784314 0.21176471 0.21568628 0.21960784 0.22352941 0.22745098\n",
            " 0.23137255 0.23529412 0.23921569 0.24313726 0.24705882 0.2509804\n",
            " 0.25490198 0.25882354 0.2627451  0.26666668 0.27058825 0.27450982\n",
            " 0.2784314  0.28235295 0.28627452 0.2901961  0.29411766 0.29803923\n",
            " 0.3019608  0.30588236 0.30980393 0.3137255  0.31764707 0.32156864\n",
            " 0.3254902  0.32941177 0.33333334 0.3372549  0.34117648 0.34509805\n",
            " 0.34901962 0.3529412  0.35686275 0.36078432 0.3647059  0.36862746\n",
            " 0.37254903 0.3764706  0.38039216 0.38431373 0.3882353  0.39215687\n",
            " 0.39607844 0.4        0.40392157 0.40784314 0.4117647  0.41568628\n",
            " 0.41960785 0.42352942 0.42745098 0.43137255 0.43529412 0.4392157\n",
            " 0.44313726 0.44705883 0.4509804  0.45490196 0.45882353 0.4627451\n",
            " 0.46666667 0.47058824 0.4745098  0.47843137 0.48235294 0.4862745\n",
            " 0.49019608 0.49411765 0.49803922 0.5019608  0.5058824  0.50980395\n",
            " 0.5137255  0.5176471  0.52156866 0.5254902  0.5294118  0.53333336\n",
            " 0.5372549  0.5411765  0.54509807 0.54901963 0.5529412  0.5568628\n",
            " 0.56078434 0.5647059  0.5686275  0.57254905 0.5764706  0.5803922\n",
            " 0.58431375 0.5882353  0.5921569  0.59607846 0.6        0.6039216\n",
            " 0.60784316 0.6117647  0.6156863  0.61960787 0.62352943 0.627451\n",
            " 0.63529414 0.6392157  0.6431373  0.6509804  0.654902   0.65882355\n",
            " 0.6627451  0.6666667  0.6745098  0.68235296 0.6901961  0.69411767\n",
            " 0.69803923 0.7137255  0.72156864 0.7254902  0.73333335 0.7411765\n",
            " 0.7529412  0.78431374 0.7882353  0.83137256 0.85882354 0.8745098\n",
            " 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.12156863 0.1254902  0.12941177 0.13333334 0.13725491\n",
            " 0.14117648 0.14509805 0.14901961 0.15294118 0.15686275 0.16078432\n",
            " 0.16470589 0.16862746 0.17254902 0.1764706  0.18039216 0.18431373\n",
            " 0.1882353  0.19215687 0.19607843 0.2        0.20392157 0.20784314\n",
            " 0.21176471 0.21568628 0.21960784 0.22352941 0.22745098 0.23137255\n",
            " 0.23529412 0.23921569 0.24313726 0.24705882 0.2509804  0.25490198\n",
            " 0.25882354 0.2627451  0.26666668 0.27058825 0.27450982 0.2784314\n",
            " 0.28235295 0.28627452 0.2901961  0.29411766 0.29803923 0.3019608\n",
            " 0.30588236 0.30980393 0.3137255  0.31764707 0.32156864 0.3254902\n",
            " 0.32941177 0.33333334 0.3372549  0.34117648 0.34509805 0.34901962\n",
            " 0.3529412  0.35686275 0.36078432 0.3647059  0.36862746 0.37254903\n",
            " 0.3764706  0.38039216 0.38431373 0.3882353  0.39215687 0.39607844\n",
            " 0.4        0.40392157 0.40784314 0.4117647  0.41568628 0.41960785\n",
            " 0.42352942 0.42745098 0.43137255 0.43529412 0.4392157  0.44313726\n",
            " 0.44705883 0.4509804  0.45490196 0.45882353 0.4627451  0.46666667\n",
            " 0.47058824 0.4745098  0.47843137 0.48235294 0.4862745  0.49019608\n",
            " 0.49411765 0.49803922 0.5019608  0.5058824  0.50980395 0.5137255\n",
            " 0.5176471  0.52156866 0.5254902  0.5294118  0.53333336 0.5372549\n",
            " 0.5411765  0.54509807 0.54901963 0.5529412  0.5568628  0.56078434\n",
            " 0.5647059  0.5686275  0.57254905 0.5764706  0.5803922  0.58431375\n",
            " 0.5882353  0.5921569  0.59607846 0.6        0.6039216  0.60784316\n",
            " 0.6117647  0.6156863  0.61960787 0.62352943 0.6313726  0.63529414\n",
            " 0.6431373  0.6627451  0.67058825 0.6745098  0.68235296 0.69803923\n",
            " 0.7176471  0.7254902  0.73333335 0.7372549  0.74509805 0.78431374\n",
            " 0.7882353  0.7921569  0.79607844 0.85490197 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.13725491 0.14117648 0.14509805 0.14901961 0.15294118\n",
            " 0.15686275 0.16078432 0.16470589 0.16862746 0.17254902 0.1764706\n",
            " 0.18039216 0.18431373 0.1882353  0.19215687 0.19607843 0.2\n",
            " 0.20392157 0.20784314 0.21176471 0.21568628 0.21960784 0.22352941\n",
            " 0.22745098 0.23137255 0.23529412 0.23921569 0.24313726 0.24705882\n",
            " 0.2509804  0.25490198 0.25882354 0.2627451  0.26666668 0.27058825\n",
            " 0.27450982 0.2784314  0.28235295 0.28627452 0.2901961  0.29411766\n",
            " 0.29803923 0.3019608  0.30588236 0.30980393 0.3137255  0.31764707\n",
            " 0.32156864 0.3254902  0.32941177 0.33333334 0.3372549  0.34117648\n",
            " 0.34509805 0.34901962 0.3529412  0.35686275 0.36078432 0.3647059\n",
            " 0.36862746 0.37254903 0.3764706  0.38039216 0.38431373 0.3882353\n",
            " 0.39215687 0.39607844 0.4        0.40392157 0.40784314 0.4117647\n",
            " 0.41568628 0.41960785 0.42352942 0.42745098 0.43137255 0.43529412\n",
            " 0.4392157  0.44313726 0.44705883 0.4509804  0.45490196 0.45882353\n",
            " 0.4627451  0.46666667 0.47058824 0.4745098  0.47843137 0.48235294\n",
            " 0.4862745  0.49019608 0.49411765 0.49803922 0.5019608  0.5058824\n",
            " 0.50980395 0.5137255  0.5176471  0.52156866 0.5254902  0.5294118\n",
            " 0.53333336 0.5372549  0.5411765  0.54509807 0.54901963 0.5529412\n",
            " 0.5568628  0.56078434 0.5647059  0.5686275  0.57254905 0.5764706\n",
            " 0.5803922  0.58431375 0.5882353  0.5921569  0.59607846 0.6\n",
            " 0.6039216  0.60784316 0.6117647  0.6156863  0.61960787 0.62352943\n",
            " 0.627451   0.6313726  0.63529414 0.6392157  0.6431373  0.64705884\n",
            " 0.6509804  0.654902   0.65882355 0.6627451  0.6666667  0.67058825\n",
            " 0.6745098  0.6784314  0.68235296 0.6862745  0.6901961  0.69411767\n",
            " 0.69803923 0.7019608  0.7058824  0.70980394 0.7137255  0.7176471\n",
            " 0.72156864 0.7254902  0.7294118  0.73333335 0.7372549  0.74509805\n",
            " 0.7490196  0.7529412  0.75686276 0.7607843  0.76862746 0.77254903\n",
            " 0.7764706  0.78431374 0.7921569  0.8117647  0.8392157  0.85490197\n",
            " 0.8627451  0.87058824 0.92156863 0.9490196  0.95686275 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.12941177 0.13333334 0.13725491 0.14117648 0.14509805\n",
            " 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746\n",
            " 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687\n",
            " 0.19607843 0.2        0.20392157 0.20784314 0.21176471 0.21568628\n",
            " 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569\n",
            " 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451\n",
            " 0.26666668 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452\n",
            " 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236 0.30980393\n",
            " 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177 0.33333334\n",
            " 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412  0.35686275\n",
            " 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216\n",
            " 0.38431373 0.3882353  0.39215687 0.39607844 0.4        0.40392157\n",
            " 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098\n",
            " 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804\n",
            " 0.45490196 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098\n",
            " 0.47843137 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922\n",
            " 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471  0.52156866\n",
            " 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765  0.54509807\n",
            " 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275\n",
            " 0.57254905 0.5764706  0.5803922  0.58431375 0.5882353  0.5921569\n",
            " 0.59607846 0.6        0.6039216  0.60784316 0.6117647  0.6156863\n",
            " 0.61960787 0.62352943 0.627451   0.6313726  0.63529414 0.6392157\n",
            " 0.6431373  0.64705884 0.6509804  0.654902   0.65882355 0.6627451\n",
            " 0.6666667  0.67058825 0.6745098  0.6784314  0.68235296 0.6862745\n",
            " 0.6901961  0.69411767 0.69803923 0.7019608  0.70980394 0.7137255\n",
            " 0.7176471  0.72156864 0.7254902  0.7294118  0.73333335 0.7372549\n",
            " 0.7411765  0.74509805 0.7529412  0.75686276 0.7607843  0.78039217\n",
            " 0.78431374 0.7882353  0.8        0.8117647  0.8352941  0.84705883\n",
            " 0.8509804  0.8627451  0.8784314  0.8901961  1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.1254902  0.12941177 0.14901961 0.15294118 0.15686275\n",
            " 0.16078432 0.16470589 0.16862746 0.17254902 0.1764706  0.18039216\n",
            " 0.18431373 0.1882353  0.19215687 0.19607843 0.2        0.20392157\n",
            " 0.20784314 0.21176471 0.21568628 0.21960784 0.22352941 0.22745098\n",
            " 0.23137255 0.23529412 0.23921569 0.24313726 0.24705882 0.2509804\n",
            " 0.25490198 0.25882354 0.2627451  0.26666668 0.27058825 0.27450982\n",
            " 0.2784314  0.28235295 0.28627452 0.2901961  0.29411766 0.29803923\n",
            " 0.3019608  0.30588236 0.30980393 0.3137255  0.31764707 0.32156864\n",
            " 0.3254902  0.32941177 0.33333334 0.3372549  0.34117648 0.34509805\n",
            " 0.34901962 0.3529412  0.35686275 0.36078432 0.3647059  0.36862746\n",
            " 0.37254903 0.3764706  0.38039216 0.38431373 0.3882353  0.39215687\n",
            " 0.39607844 0.4        0.40392157 0.40784314 0.4117647  0.41568628\n",
            " 0.41960785 0.42352942 0.42745098 0.43137255 0.43529412 0.4392157\n",
            " 0.44313726 0.44705883 0.4509804  0.45490196 0.45882353 0.4627451\n",
            " 0.46666667 0.47058824 0.4745098  0.47843137 0.48235294 0.4862745\n",
            " 0.49019608 0.49411765 0.49803922 0.5019608  0.5058824  0.50980395\n",
            " 0.5137255  0.5176471  0.52156866 0.5254902  0.5294118  0.53333336\n",
            " 0.5372549  0.5411765  0.54509807 0.54901963 0.5529412  0.5568628\n",
            " 0.56078434 0.5647059  0.5686275  0.57254905 0.5764706  0.5803922\n",
            " 0.58431375 0.5882353  0.5921569  0.59607846 0.6        0.6039216\n",
            " 0.60784316 0.6117647  0.6156863  0.61960787 0.62352943 0.627451\n",
            " 0.6313726  0.63529414 0.6392157  0.6431373  0.64705884 0.6509804\n",
            " 0.654902   0.65882355 0.6627451  0.6666667  0.67058825 0.6745098\n",
            " 0.6784314  0.68235296 0.6862745  0.6901961  0.69411767 0.69803923\n",
            " 0.7019608  0.7058824  0.70980394 0.7137255  0.7176471  0.72156864\n",
            " 0.7254902  0.7294118  0.73333335 0.7372549  0.7411765  0.74509805\n",
            " 0.7490196  0.75686276 0.7607843  0.7647059  0.76862746 0.77254903\n",
            " 0.7764706  0.78039217 0.78431374 0.7882353  0.79607844 0.80784315\n",
            " 0.8156863  0.8235294  0.83137256 0.8352941  0.85882354 0.8784314\n",
            " 0.8980392  0.9019608  0.92156863 0.92941177 0.9490196  0.95686275\n",
            " 0.9764706  1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.10980392 0.13333334 0.13725491 0.14117648 0.14509805\n",
            " 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746\n",
            " 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687\n",
            " 0.19607843 0.2        0.20392157 0.20784314 0.21176471 0.21568628\n",
            " 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569\n",
            " 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451\n",
            " 0.26666668 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452\n",
            " 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236 0.30980393\n",
            " 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177 0.33333334\n",
            " 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412  0.35686275\n",
            " 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216\n",
            " 0.38431373 0.3882353  0.39215687 0.39607844 0.4        0.40392157\n",
            " 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098\n",
            " 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804\n",
            " 0.45490196 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098\n",
            " 0.47843137 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922\n",
            " 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471  0.52156866\n",
            " 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765  0.54509807\n",
            " 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275\n",
            " 0.57254905 0.5764706  0.5803922  0.58431375 0.5882353  0.5921569\n",
            " 0.59607846 0.6        0.6039216  0.60784316 0.6117647  0.6156863\n",
            " 0.61960787 0.62352943 0.627451   0.6313726  0.63529414 0.6392157\n",
            " 0.6431373  0.64705884 0.6509804  0.654902   0.65882355 0.6627451\n",
            " 0.6666667  0.67058825 0.6745098  0.6784314  0.68235296 0.6901961\n",
            " 0.69411767 0.7019608  0.7137255  0.7176471  0.72156864 0.7254902\n",
            " 0.7294118  0.7372549  0.7411765  0.74509805 0.7647059  0.7764706\n",
            " 0.78431374 0.8        0.8117647  0.85882354 0.8627451  0.89411765\n",
            " 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.12156863 0.1254902  0.13333334 0.13725491 0.14117648\n",
            " 0.14509805 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589\n",
            " 0.16862746 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353\n",
            " 0.19215687 0.19607843 0.2        0.20392157 0.20784314 0.21176471\n",
            " 0.21568628 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412\n",
            " 0.23921569 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354\n",
            " 0.2627451  0.26666668 0.27058825 0.27450982 0.2784314  0.28235295\n",
            " 0.28627452 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236\n",
            " 0.30980393 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177\n",
            " 0.33333334 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412\n",
            " 0.35686275 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706\n",
            " 0.38039216 0.38431373 0.3882353  0.39215687 0.39607844 0.4\n",
            " 0.40392157 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942\n",
            " 0.42745098 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883\n",
            " 0.4509804  0.45490196 0.45882353 0.4627451  0.46666667 0.47058824\n",
            " 0.4745098  0.47843137 0.48235294 0.4862745  0.49019608 0.49411765\n",
            " 0.49803922 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471\n",
            " 0.52156866 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765\n",
            " 0.54509807 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059\n",
            " 0.5686275  0.57254905 0.5764706  0.5803922  0.58431375 0.5882353\n",
            " 0.5921569  0.59607846 0.6        0.6039216  0.60784316 0.6117647\n",
            " 0.6156863  0.61960787 0.627451   0.6313726  0.64705884 0.6509804\n",
            " 0.654902   0.6784314  0.68235296 0.6862745  0.69803923 0.70980394\n",
            " 0.7176471  0.72156864 0.7294118  0.7372549  0.7411765  0.7529412\n",
            " 0.78039217 0.78431374 0.7921569  0.8        0.8039216  0.8235294\n",
            " 0.8509804  0.8666667  0.8784314  0.9019608  0.9137255  0.9254902\n",
            " 0.93333334 0.9411765  0.96862745 0.98039216 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.10196079 0.1254902  0.12941177 0.13333334 0.13725491\n",
            " 0.14117648 0.14509805 0.14901961 0.15294118 0.15686275 0.16078432\n",
            " 0.16470589 0.16862746 0.17254902 0.1764706  0.18039216 0.18431373\n",
            " 0.1882353  0.19215687 0.19607843 0.2        0.20392157 0.20784314\n",
            " 0.21176471 0.21568628 0.21960784 0.22352941 0.22745098 0.23137255\n",
            " 0.23529412 0.23921569 0.24313726 0.24705882 0.2509804  0.25490198\n",
            " 0.25882354 0.2627451  0.26666668 0.27058825 0.27450982 0.2784314\n",
            " 0.28235295 0.28627452 0.2901961  0.29411766 0.29803923 0.3019608\n",
            " 0.30588236 0.30980393 0.3137255  0.31764707 0.32156864 0.3254902\n",
            " 0.32941177 0.33333334 0.3372549  0.34117648 0.34509805 0.34901962\n",
            " 0.3529412  0.35686275 0.36078432 0.3647059  0.36862746 0.37254903\n",
            " 0.3764706  0.38039216 0.38431373 0.3882353  0.39215687 0.39607844\n",
            " 0.4        0.40392157 0.40784314 0.4117647  0.41568628 0.41960785\n",
            " 0.42352942 0.42745098 0.43137255 0.43529412 0.4392157  0.44313726\n",
            " 0.44705883 0.4509804  0.45490196 0.45882353 0.4627451  0.46666667\n",
            " 0.47058824 0.4745098  0.47843137 0.48235294 0.4862745  0.49019608\n",
            " 0.49411765 0.49803922 0.5019608  0.5058824  0.50980395 0.5137255\n",
            " 0.5176471  0.52156866 0.5254902  0.5294118  0.53333336 0.5372549\n",
            " 0.5411765  0.54509807 0.54901963 0.5529412  0.5568628  0.56078434\n",
            " 0.5647059  0.5686275  0.57254905 0.5764706  0.5803922  0.58431375\n",
            " 0.5882353  0.59607846 0.6039216  0.60784316 0.6117647  0.6156863\n",
            " 0.627451   0.6313726  0.63529414 0.6431373  0.64705884 0.6509804\n",
            " 0.654902   0.65882355 0.6627451  0.6666667  0.6745098  0.6784314\n",
            " 0.6862745  0.7058824  0.7176471  0.72156864 0.7254902  0.7294118\n",
            " 0.73333335 0.7411765  0.76862746 0.77254903 0.7921569  0.8\n",
            " 0.8039216  0.80784315 0.83137256 0.84705883 0.8666667  0.8862745\n",
            " 0.89411765 0.8980392  0.9019608  0.9098039  0.9137255  0.92156863\n",
            " 0.9254902  0.9529412  0.99215686 1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n",
            "[0.         0.09803922 0.10980392 0.11372549 0.11764706 0.12156863\n",
            " 0.1254902  0.12941177 0.13333334 0.13725491 0.14117648 0.14509805\n",
            " 0.14901961 0.15294118 0.15686275 0.16078432 0.16470589 0.16862746\n",
            " 0.17254902 0.1764706  0.18039216 0.18431373 0.1882353  0.19215687\n",
            " 0.19607843 0.2        0.20392157 0.20784314 0.21176471 0.21568628\n",
            " 0.21960784 0.22352941 0.22745098 0.23137255 0.23529412 0.23921569\n",
            " 0.24313726 0.24705882 0.2509804  0.25490198 0.25882354 0.2627451\n",
            " 0.26666668 0.27058825 0.27450982 0.2784314  0.28235295 0.28627452\n",
            " 0.2901961  0.29411766 0.29803923 0.3019608  0.30588236 0.30980393\n",
            " 0.3137255  0.31764707 0.32156864 0.3254902  0.32941177 0.33333334\n",
            " 0.3372549  0.34117648 0.34509805 0.34901962 0.3529412  0.35686275\n",
            " 0.36078432 0.3647059  0.36862746 0.37254903 0.3764706  0.38039216\n",
            " 0.38431373 0.3882353  0.39215687 0.39607844 0.4        0.40392157\n",
            " 0.40784314 0.4117647  0.41568628 0.41960785 0.42352942 0.42745098\n",
            " 0.43137255 0.43529412 0.4392157  0.44313726 0.44705883 0.4509804\n",
            " 0.45490196 0.45882353 0.4627451  0.46666667 0.47058824 0.4745098\n",
            " 0.47843137 0.48235294 0.4862745  0.49019608 0.49411765 0.49803922\n",
            " 0.5019608  0.5058824  0.50980395 0.5137255  0.5176471  0.52156866\n",
            " 0.5254902  0.5294118  0.53333336 0.5372549  0.5411765  0.54509807\n",
            " 0.54901963 0.5529412  0.5568628  0.56078434 0.5647059  0.5686275\n",
            " 0.57254905 0.5764706  0.5803922  0.58431375 0.5882353  0.5921569\n",
            " 0.59607846 0.6        0.6039216  0.60784316 0.61960787 0.62352943\n",
            " 0.627451   0.6313726  0.63529414 0.6392157  0.6431373  0.64705884\n",
            " 0.6509804  0.654902   0.6627451  0.67058825 0.6784314  0.6862745\n",
            " 0.69411767 0.69803923 0.7019608  0.7058824  0.70980394 0.7137255\n",
            " 0.7176471  0.72156864 0.7254902  0.7294118  0.73333335 0.7490196\n",
            " 0.75686276 0.7607843  0.7647059  0.76862746 0.78039217 0.78431374\n",
            " 0.8039216  0.81960785 0.83137256 0.8352941  0.8509804  0.8627451\n",
            " 0.8666667  0.8745098  0.88235295 0.8862745  0.8901961  0.89411765\n",
            " 0.90588236 0.91764706 0.93333334 0.9372549  0.9411765  1.        ]\n",
            "1.0\n",
            "0.0\n",
            "(240, 240, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-05 18:31:56.769554: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "# Create the train, val and test split with the pairings\n",
        "\n",
        "train_dataset = get_dataset(\n",
        "    batch_size,\n",
        "    image_size,\n",
        "    train_image,\n",
        "    train_mask,)\n",
        "\n",
        "val_dataset = get_dataset(\n",
        "    batch_size, \n",
        "    image_size, \n",
        "    val_image, \n",
        "    val_mask, )\n",
        "\n",
        "test_dataset = get_dataset(\n",
        "    batch_size, \n",
        "    image_size, \n",
        "    test_image, \n",
        "    test_mask, )\n",
        "\n",
        "for batch in train_dataset.take(1): \n",
        "    images, masks = batch\n",
        "    print(images.shape)\n",
        "    print(masks.shape)\n",
        "\n",
        "for image in images: \n",
        "    print(np.unique(image))\n",
        "    print(np.max(image))\n",
        "    print(np.min(image))\n",
        "    print(image.shape)\n",
        "\n",
        "# # Check values in the first batch\n",
        "# for input_img, target_img in train_dataset.take(10):\n",
        "#     print(\"Information of image:\\n\", np.max(input_img), np.min(input_img), input_img.dtype)\n",
        "#     print(\"Information of mask:\\n\", np.max(target_img), np.min(target_img), target_img.dtype, np.unique(target_img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1e-6\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def weighted_binary_crossentropy(beta=0.9):\n",
        "    def loss(y_true, y_pred):\n",
        "        weight_for_1 = beta\n",
        "        weight_for_0 = 1 - beta\n",
        "        \n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        \n",
        "        loss = -(weight_for_1 * y_true * tf.math.log(y_pred + 1e-7) +\n",
        "                 weight_for_0 * (1 - y_true) * tf.math.log(1 - y_pred + 1e-7))\n",
        "        \n",
        "        return tf.reduce_mean(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wJjF_CBz7k2G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/research/miniconda3/envs/unet/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 240, 240, 1))\n",
            "  warnings.warn(msg)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1741217520.818243  153479 service.cc:148] XLA service 0x7ea95800e590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1741217520.818271  153479 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
            "2025-03-05 18:32:00.930551: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1741217521.314652  153479 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "I0000 00:00:1741217533.556822  153479 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2025-03-05 18:32:39.959461: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_16', 128 bytes spill stores, 128 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "194/194 - 46s - 237ms/step - loss: 1.1588 - val_loss: 1.0000\n",
            "Epoch 2/5\n",
            "194/194 - 20s - 102ms/step - loss: 1.1916 - val_loss: 1.0000\n",
            "Epoch 3/5\n",
            "194/194 - 20s - 103ms/step - loss: 1.1916 - val_loss: 1.0000\n",
            "Epoch 4/5\n",
            "194/194 - 20s - 103ms/step - loss: 1.1916 - val_loss: 1.0000\n",
            "Epoch 5/5\n",
            "194/194 - 20s - 103ms/step - loss: 1.1916 - val_loss: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eaaa7b5a3b0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loss_fn = dice_loss if loss_type == 'dice' else weighted_binary_crossentropy(beta=0.9)\n",
        "\n",
        "class_weights = {0: 1.0, 1: 10.0}\n",
        "\n",
        "# Configure the model for training.\n",
        "# We use the \"sparse\" version of categorical_crossentropy\n",
        "# because our target data is integers.\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4), \n",
        "    loss=dice_loss, \n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\", save_best_only=True),\n",
        "    keras.callbacks.CSVLogger(filename=\"cvslog.csv\", separator=\",\", append=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 5\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A_TdKzTh7k2G"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/research/miniconda3/envs/unet/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(16, 240, 240, 1))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/jpeg": "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",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAIAAACxN37FAAAFFUlEQVR4Ae3c6ZKqMBAG0PHWvP8re3GsshBxwaQ7hJz5BQpZTj7a1Gw/P74IECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAYAyB8/k8xkTrzPJUpxmt1BZYzfHpZL3eQAN6A5T/9mqU58MQ67nG4vjf4txpW4G3aW47vP33/rv/IY4wQjmutcoqdC3J79vZmuat138/sg7vtIduvGgl6bSZflw8FfrRJO+VkjRPoyy8PW+eiT2p0InY911FxFHNVqHvU9b5WcRD0heJCt1mvTKTN1TZVqEbBDozzdP0krtrADrrUqBnGA77F/CDlf7X8H4G8w3GULX5yqBC38ch/iw0ZPM0T1NZnMZPrn0PKnT7NQgdwWiZVqFD47RsPLQ8Lzsb8lygU5d9tHqZivvXmUDnmwf26BNAoAPj9di0wD2a1H1FoOt6aq2xgECnLsBO9tDTB8VRPyv8LkdqoK+dhYbp2TOz2umzixugVOpSha4EuaWZ5BhdqvGT/4Xw7PUts9nXtQLdZj2SM/1ikgfLtEC/WOvu37pU5ie1eT63T66ZX7/nY4FutjqhRfovySP+yyW/y9Es0EEdH6ncfkGkQn+BdrRbQj8rkrFU6GTwS3eDF9FQcRU6lHelcWleQan3kkDXs+yzpSPtN6YVEOjsGB4sQNl87/oT6HdCvb2/6YHZdHEXEgLdxTJ9OsgpoIPv0QX606xUvC6uLg6e5mmNBLpiUDtrKu65aggh0A3xW3Z9yDRPoALdJlVt89S291BxgQ7l1Xi2gEBni9/6a1UmW/V7m3jogT/BCuX9tPG0704cO80Ttwr9aeZCr5tydviohQLeGhfoG0X7A7EuXwOBLjes3IJSXQJqD12iF3tv3Y31IM+JCh0bypLWK0awYlMlM0q4V4VOQK7QRUm1HifNE7Q/waqQtt02MVSUr6sg0LtNY9HABoyyQBclZrc3Dxvl64rYQ+82mcuBvd5GD57jJZZzAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBFYH/fsl+cJb3QkMAAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=240x240>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCADwAPABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiv/9k=",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAABFElEQVR4Ae3QMQEAAADCoPVPbQZ/iEBhwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGDBgwIABAwYMGPgGBuHwAAGAvqFlAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=240x240>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate predictions for all images in the validation set\n",
        "import cv2 as cv\n",
        "\n",
        "test_prediction = model.predict(test_dataset)\n",
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(test_prediction[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = ImageOps.autocontrast(keras.utils.array_to_img(mask))\n",
        "    display(img)\n",
        "    cv.imwrite(\"mask.png\", mask)\n",
        "\n",
        "# Display results for validation image #10\n",
        "i = 50\n",
        "\n",
        "# Display input image\n",
        "display(Image(filename=test_image[i])) # test_image is a list\n",
        "img = cv.imread(test_image[i])\n",
        "cv.imwrite(\"original.png\", img)\n",
        "\n",
        "# Display ground-truth target mask\n",
        "img = ImageOps.autocontrast(load_img(test_mask[i])) # test_mask is also a list\n",
        "display(img)\n",
        "img = cv.imread(test_mask[i])\n",
        "cv.imwrite(\"ground_truth.png\", img)\n",
        "\n",
        "# Display mask predicted by our model\n",
        "display_mask(i)  # Note that the model only sees inputs at 150x150.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/research/miniconda3/envs/unet/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(16, 240, 240, 1))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m193/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/research/miniconda3/envs/unet/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 240, 240, 1))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step\n"
          ]
        }
      ],
      "source": [
        "# obtain the predictions\n",
        "train_prediction = model.predict(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [194, 3095]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y_prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_prediction)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Create confusion matrix and normalizes it over predicted (columns)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/metrics/_classification.py:340\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 340\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [194, 3095]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Predict\n",
        "y_prediction = model.predict(train_prediction)\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(train_dataset, y_prediction , normalize='pred')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/research/miniconda3/envs/unet/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(32, 240, 240, 1))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [194, 3095]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y_prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_prediction)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Create confusion matrix and normalizes it over predicted (columns)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate predictions for all images in the validation set\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/metrics/_classification.py:340\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 340\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [194, 3095]"
          ]
        }
      ],
      "source": [
        "# Generate predictions for all images in the validation set\n",
        "import cv2 as cv\n",
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(train_prediction[i], axis=-1) \n",
        "    # print(np.unique(mask))\n",
        "    # print(mask.shape)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    mask = mask * (255 // (np.max(mask) + 1))  # Normalize the mask to [0, 255]\n",
        "    img = ImageOps.autocontrast(keras.utils.array_to_img(mask))\n",
        "    display(img)\n",
        "    cv.imwrite(\"mask.png\", mask)\n",
        "\n",
        "# Display results for training image\n",
        "i = 99\n",
        "\n",
        "# # Display input image\n",
        "# display(Image(filename=train_image[i])) \n",
        "# img = cv.imread(train_image[i])\n",
        "# cv.imwrite(\"original.png\", img)\n",
        "\n",
        "# Display ground-truth target mask\n",
        "img = ImageOps.autocontrast(load_img(train_mask[i])) # test_mask is also a list\n",
        "display(img)\n",
        "img = cv.imread(train_mask[i])\n",
        "cv.imwrite(\"ground_truth.png\", img)\n",
        "\n",
        "# Display mask predicted by our model\n",
        "display_mask(i)  # Note that the model only sees inputs at 150x150.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/jpeg": "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",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAIAAACxN37FAAAEJElEQVR4Ae3a0Y6DIBAF0Lr//8+7Zk2sUVSKjEh6+mRRQc7cEtr09fIiQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIDA1wn8/r++btpVJzxU7U1nHwuMGU7eMwxKk4Q5aaR2AhR3ei/KyxHFeqmRc/yTc5FrWgnkhL7Vsz1zXIF+Zl3eTyXTb4uMI4HOQGp9iUznV8AeOt+q5pVlGbWlPq2BFfqU6EEXlH0MHjSB+EcR6HjjqiPI9DGnQB/7ONuZgEA3KFjxKjvuoadtdHEPDWZ775C+FN7kHRHBKdw3TaCTYazQdxQqIs13PHeHYwh0eNGkOZx4MYBALzACDqU5APWoS4E+0rl4TpovAhbcLtAFaI+4xTfCZBkEOsmisVcBgQ6snEU0EHena4HegdHcp4BAx9bNIh3ru+ldoDckGnoWEOieq+fZNwICvSGp3RC06/Ajd7JQAp1kqdwo05VB97vzb7t9m7AzFRfXoI9K2NTDOxbocOKDAa4nW6BXvAK9AmnztjjZAr0qmD30CqTN2zGXolmF3gpdhTGkk3nZnrM+t0zjze0hw+uUAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIJAv8AcBe0ghzzwa8gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=240x240>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display results for validation image #10\n",
        "i = 200\n",
        "\n",
        "# # Display input image\n",
        "display(Image(filename=test_image[i])) # test_image is a list\n",
        "\n",
        "# # Display ground-truth target mask\n",
        "img = ImageOps.autocontrast(load_img(test_mask[i])) # test_mask is also a list\n",
        "display(img)\n",
        "\n",
        "# # Display mask predicted by our model\n",
        "# display_mask(i)  # Note that the model only sees inputs at 150x150.\n",
        "\n",
        "og_img = cv.imread(test_image[i])\n",
        "mask_img = cv.imread(test_mask[i])\n",
        "\n",
        "multiplied = og_img*mask_img\n",
        "\n",
        "cv.imshow(\"multiplied\", multiplied)\n",
        "# waits for user to press any key\n",
        "# (this is necessary to avoid Python kernel form crashing)\n",
        "cv.waitKey(0)\n",
        "\n",
        "# closing all open windows\n",
        "cv.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images shape: (16, 240, 240, 1)\n",
            "Images min/max: tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "Masks shape: (16, 240, 240, 1)\n",
            "Unique mask values: [0.]\n",
            "Images shape: (16, 240, 240, 1)\n",
            "Images min/max: tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "Masks shape: (16, 240, 240, 1)\n",
            "Unique mask values: [0.]\n",
            "Images shape: (16, 240, 240, 1)\n",
            "Images min/max: tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "Masks shape: (16, 240, 240, 1)\n",
            "Unique mask values: [0.]\n",
            "Images shape: (16, 240, 240, 1)\n",
            "Images min/max: tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "Masks shape: (16, 240, 240, 1)\n",
            "Unique mask values: [0.]\n",
            "Images shape: (16, 240, 240, 1)\n",
            "Images min/max: tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "Masks shape: (16, 240, 240, 1)\n",
            "Unique mask values: [0.]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-16 20:06:05.327160: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "# Add this after loading a batch\n",
        "for images, masks in train_dataset.take(5):\n",
        "    print(\"Images shape:\", images.shape)\n",
        "    print(\"Images min/max:\", tf.reduce_min(images), tf.reduce_max(images))\n",
        "    print(\"Masks shape:\", masks.shape)\n",
        "    print(\"Unique mask values:\", np.unique(masks))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "oxford_pets_image_segmentation",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "unet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

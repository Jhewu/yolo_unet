{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:11:52.794670Z",
     "iopub.status.busy": "2021-12-28T12:11:52.794352Z",
     "iopub.status.idle": "2021-12-28T12:11:56.710275Z",
     "shell.execute_reply": "2021-12-28T12:11:56.709474Z",
     "shell.execute_reply.started": "2021-12-28T12:11:52.794582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to find torch_shm_manager at /home/research/.local/lib/python3.10/site-packages/torch/bin/torch_shm_manager",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/torch/__init__.py:1954\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find torch_shm_manager at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path)\n\u001b[1;32m   1951\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1954\u001b[0m _C\u001b[38;5;241m.\u001b[39m_initExtension(\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unet/lib/python3.10/site-packages/torch/__init__.py:1950\u001b[0m, in \u001b[0;36m_manager_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1948\u001b[0m prepare_multiprocessing_environment(get_file_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find torch_shm_manager at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path)\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to find torch_shm_manager at /home/research/.local/lib/python3.10/site-packages/torch/bin/torch_shm_manager"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as tt\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device\n",
    "Set device to use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:11:56.715857Z",
     "iopub.status.busy": "2021-12-28T12:11:56.715370Z",
     "iopub.status.idle": "2021-12-28T12:11:56.774230Z",
     "shell.execute_reply": "2021-12-28T12:11:56.773512Z",
     "shell.execute_reply.started": "2021-12-28T12:11:56.715817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed\n",
    "\n",
    "Set seed for reproducibilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:11:56.779616Z",
     "iopub.status.busy": "2021-12-28T12:11:56.778783Z",
     "iopub.status.idle": "2021-12-28T12:11:56.791667Z",
     "shell.execute_reply": "2021-12-28T12:11:56.790971Z",
     "shell.execute_reply.started": "2021-12-28T12:11:56.779574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 0):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files path in a dataframe\n",
    "\n",
    "We first load the path of all the image files as well as their corresponding mask files in a dataframe. \n",
    "\n",
    "We also create a function `diagnonsis` which will read through all the mask files and return those files which have numpy value > 0 (not blank black mask images).\n",
    "We then add the list of non blank mask images as a diagnonsis column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:11:56.797994Z",
     "iopub.status.busy": "2021-12-28T12:11:56.796403Z",
     "iopub.status.idle": "2021-12-28T12:12:21.707855Z",
     "shell.execute_reply": "2021-12-28T12:12:21.707100Z",
     "shell.execute_reply.started": "2021-12-28T12:11:56.797955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = '../input/lgg-mri-segmentation/kaggle_3m/'\n",
    "\n",
    "mask_files = glob.glob(ROOT_PATH + '*/*_mask*')\n",
    "image_files = [file.replace('_mask', '') for file in mask_files]\n",
    "\n",
    "def diagnosis(mask_path):\n",
    "    return 1 if np.max(cv2.imread(mask_path)) > 0 else 0\n",
    "\n",
    "files_df = pd.DataFrame({\"image_path\": image_files,\n",
    "                  \"mask_path\": mask_files,\n",
    "                  \"diagnosis\": [diagnosis(x) for x in mask_files]})\n",
    "\n",
    "files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:21.710308Z",
     "iopub.status.busy": "2021-12-28T12:12:21.710094Z",
     "iopub.status.idle": "2021-12-28T12:12:21.950503Z",
     "shell.execute_reply": "2021-12-28T12:12:21.949771Z",
     "shell.execute_reply.started": "2021-12-28T12:12:21.710282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ax = files_df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(6,6), color=['green', 'red'])\n",
    "ax.set_title('Data Distribution', fontsize=15)\n",
    "ax.set_ylabel('No. of Images', fontsize=15)\n",
    "ax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\n",
    "for i, rows in enumerate(files_df['diagnosis'].value_counts().values):\n",
    "    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 3929 samples, out of which 1373 are tumor positive, and 2556 are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test split\n",
    "\n",
    "We split the data into train, validation and test datasets using the `tran_test_split` function from **sklearn**. We use `stratify` parameter to evenly distribute the number of tumor positive samples among each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:21.952379Z",
     "iopub.status.busy": "2021-12-28T12:12:21.951929Z",
     "iopub.status.idle": "2021-12-28T12:12:21.975614Z",
     "shell.execute_reply": "2021-12-28T12:12:21.974742Z",
     "shell.execute_reply.started": "2021-12-28T12:12:21.952328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(files_df, stratify=files_df['diagnosis'], test_size=0.1, random_state=0)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "train_df, test_df = train_test_split(train_df, stratify=train_df['diagnosis'], test_size=0.15, random_state=0)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:21.978759Z",
     "iopub.status.busy": "2021-12-28T12:12:21.978100Z",
     "iopub.status.idle": "2021-12-28T12:12:22.821569Z",
     "shell.execute_reply": "2021-12-28T12:12:22.820552Z",
     "shell.execute_reply.started": "2021-12-28T12:12:21.978714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "images, masks = [], []\n",
    "df_positive = train_df[train_df['diagnosis']==1].sample(5).values\n",
    "\n",
    "for sample in df_positive:\n",
    "    img = cv2.imread(sample[0])\n",
    "    mask = cv2.imread(sample[1])\n",
    "    images.append(img)\n",
    "    masks.append(mask)\n",
    "images = np.hstack(np.array(images))\n",
    "masks = np.hstack(np.array(masks))\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.4)\n",
    "\n",
    "grid[0].imshow(images)\n",
    "grid[0].set_title('Images', fontsize=15)\n",
    "grid[0].axis('off')\n",
    "grid[1].imshow(masks)\n",
    "grid[1].set_title('Masks', fontsize=15)\n",
    "grid[1].axis('off')\n",
    "grid[2].imshow(images)\n",
    "grid[2].imshow(masks, alpha=0.4)\n",
    "grid[2].set_title('Brain MRI with mask', fontsize=15)\n",
    "grid[2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to PyTorch dataset format\n",
    "\n",
    "We load the images & masks using **cv2**, and then divide by 225 after converting them to NumPy array, so that all images/masks are in the range of [0,1].\n",
    "Then we apply transformations to it using the Albumentations library. \n",
    "\n",
    "For the images, we first convert them from `HxWxC` to `CxHxW` format, then to `torch.tensor` of type `float32`, & then finally Normalize the color channels.\n",
    "\n",
    "For the masks, since they only have `HxW`, we add another dimension so it becomes `HxWxC`, then we convert it to `CxHxW`. Then we convert it to `torch.tensor` of type `float32`. We don't need to normalize the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.822813Z",
     "iopub.status.busy": "2021-12-28T12:12:22.822581Z",
     "iopub.status.idle": "2021-12-28T12:12:22.836918Z",
     "shell.execute_reply": "2021-12-28T12:12:22.835803Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.822779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BrainDataset(data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.df.iloc[idx, 0])\n",
    "        image = np.array(image)/255.\n",
    "        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n",
    "        mask = np.array(mask)/255.\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=image, mask=mask)\n",
    "            image = aug['image']\n",
    "            mask = aug['mask']\n",
    "        \n",
    "        image = image.transpose((2,0,1))\n",
    "        image = torch.from_numpy(image).type(torch.float32)\n",
    "        image = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n",
    "        mask = np.expand_dims(mask, axis=-1).transpose((2,0,1))\n",
    "        mask = torch.from_numpy(mask).type(torch.float32)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.839415Z",
     "iopub.status.busy": "2021-12-28T12:12:22.838787Z",
     "iopub.status.idle": "2021-12-28T12:12:22.851298Z",
     "shell.execute_reply": "2021-12-28T12:12:22.850551Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.839370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(width=128, height=128, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(width=128, height=128, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(width=128, height=128, p=1.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.854707Z",
     "iopub.status.busy": "2021-12-28T12:12:22.854356Z",
     "iopub.status.idle": "2021-12-28T12:12:22.862156Z",
     "shell.execute_reply": "2021-12-28T12:12:22.861391Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.854669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "train_ds = BrainDataset(train_df, train_transform)\n",
    "val_ds = BrainDataset(val_df, val_transform)\n",
    "test_ds = BrainDataset(test_df, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.863932Z",
     "iopub.status.busy": "2021-12-28T12:12:22.863573Z",
     "iopub.status.idle": "2021-12-28T12:12:22.870217Z",
     "shell.execute_reply": "2021-12-28T12:12:22.869398Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.863891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dataset_info(dataset): \n",
    "    print(f'Size of dataset: {len(dataset)}')\n",
    "    index = random.randint(1, 40)\n",
    "    img, label = dataset[index]\n",
    "    print(f'Sample-{index} Image size: {img.shape}, Mask: {label.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.872110Z",
     "iopub.status.busy": "2021-12-28T12:12:22.871688Z",
     "iopub.status.idle": "2021-12-28T12:12:22.978992Z",
     "shell.execute_reply": "2021-12-28T12:12:22.978125Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.872073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Train dataset:')\n",
    "dataset_info(train_ds)\n",
    "print('Validation dataset:')\n",
    "dataset_info(val_ds)\n",
    "print('Test dataset:')\n",
    "dataset_info(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataloaders\n",
    "\n",
    "We create dataloaders to load data in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.981886Z",
     "iopub.status.busy": "2021-12-28T12:12:22.981382Z",
     "iopub.status.idle": "2021-12-28T12:12:22.991086Z",
     "shell.execute_reply": "2021-12-28T12:12:22.990224Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.981841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "set_seed()\n",
    "train_dl = DataLoader(train_ds, \n",
    "                      batch_size, \n",
    "                      shuffle=True, \n",
    "                      num_workers=2,  \n",
    "                      pin_memory=True)  \n",
    "\n",
    "set_seed()\n",
    "val_dl = DataLoader(val_ds, \n",
    "                    batch_size,   \n",
    "                    num_workers=2, \n",
    "                    pin_memory=True)\n",
    "\n",
    "test_dl = DataLoader(val_ds, \n",
    "                    batch_size,   \n",
    "                    num_workers=2, \n",
    "                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:22.996121Z",
     "iopub.status.busy": "2021-12-28T12:12:22.995824Z",
     "iopub.status.idle": "2021-12-28T12:12:28.175876Z",
     "shell.execute_reply": "2021-12-28T12:12:28.174972Z",
     "shell.execute_reply.started": "2021-12-28T12:12:22.996082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images, masks = next(iter(train_dl))\n",
    "print(images.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of one batch is `64xCx128x128` where C is the number of channels in image/mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing samples from a batch\n",
    "\n",
    "To view the samples in a batch we first need to denormalize the images by passing in same *mean* & *std*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:28.179286Z",
     "iopub.status.busy": "2021-12-28T12:12:28.178491Z",
     "iopub.status.idle": "2021-12-28T12:12:30.825312Z",
     "shell.execute_reply": "2021-12-28T12:12:30.824262Z",
     "shell.execute_reply.started": "2021-12-28T12:12:28.179238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def denormalize(images):\n",
    "    means = torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n",
    "    stds = torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n",
    "    return images * stds + means\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, masks in dl:\n",
    "        fig1, ax1 = plt.subplots(figsize=(24, 24))\n",
    "        ax1.set_xticks([]); ax1.set_yticks([])\n",
    "        denorm_images = denormalize(images)\n",
    "        ax1.imshow(make_grid(denorm_images[:13], nrow=13).permute(1, 2, 0).clamp(0,1))\n",
    "        \n",
    "        fig2, ax2 = plt.subplots(figsize=(24, 24))\n",
    "        ax2.set_xticks([]); ax2.set_yticks([])\n",
    "        ax2.imshow(make_grid(masks[:13], nrow=13).permute(1, 2, 0).clamp(0,1))\n",
    "        break\n",
    "        \n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:30.827720Z",
     "iopub.status.busy": "2021-12-28T12:12:30.827333Z",
     "iopub.status.idle": "2021-12-28T12:12:30.845102Z",
     "shell.execute_reply": "2021-12-28T12:12:30.844322Z",
     "shell.execute_reply.started": "2021-12-28T12:12:30.827671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels))\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "    \n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n",
    "                        diffY//2, diffY-diffY//2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:30.848737Z",
     "iopub.status.busy": "2021-12-28T12:12:30.848109Z",
     "iopub.status.idle": "2021-12-28T12:12:30.861069Z",
     "shell.execute_reply": "2021-12-28T12:12:30.860254Z",
     "shell.execute_reply.started": "2021-12-28T12:12:30.848705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024//factor)\n",
    "        self.up1 = Up(1024, 512//factor, bilinear)\n",
    "        self.up2 = Up(512, 256//factor, bilinear)        \n",
    "        self.up3 = Up(256, 128//factor, bilinear)        \n",
    "        self.up4 = Up(128, 64, bilinear)        \n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:30.862872Z",
     "iopub.status.busy": "2021-12-28T12:12:30.862520Z",
     "iopub.status.idle": "2021-12-28T12:12:35.990678Z",
     "shell.execute_reply": "2021-12-28T12:12:35.989688Z",
     "shell.execute_reply.started": "2021-12-28T12:12:30.862831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = UNet(3, 1).to(device)\n",
    "out = model(torch.randn(1, 3, 128, 128).to(device))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric & Loss fn\n",
    "\n",
    "\n",
    "To measure accuracy, the metric we choose is the **DICE coefficient**. *Dice Coefficient* is `2 * the Area of Overlap divided by the total number of pixels in both images`.\n",
    "\n",
    "**DICE Loss** is equal to `1 - DICE Coefficient`.\n",
    "\n",
    "However, a better loss function is the `sum of BCELoss & DICE Loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:35.992602Z",
     "iopub.status.busy": "2021-12-28T12:12:35.992156Z",
     "iopub.status.idle": "2021-12-28T12:12:36.001054Z",
     "shell.execute_reply": "2021-12-28T12:12:36.000115Z",
     "shell.execute_reply.started": "2021-12-28T12:12:35.992559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dice_coef_metric(pred, label):\n",
    "    intersection = 2.0 * (pred * label).sum()\n",
    "    union = pred.sum() + label.sum()\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1.\n",
    "    return intersection / union\n",
    "\n",
    "def dice_coef_loss(pred, label):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * (pred * label).sum() + smooth\n",
    "    union = pred.sum() + label.sum() + smooth\n",
    "    return 1 - (intersection / union)\n",
    "\n",
    "def bce_dice_loss(pred, label):\n",
    "    dice_loss = dice_coef_loss(pred, label)\n",
    "    bce_loss = nn.BCELoss()(pred, label)\n",
    "    return dice_loss + bce_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:36.003284Z",
     "iopub.status.busy": "2021-12-28T12:12:36.002747Z",
     "iopub.status.idle": "2021-12-28T12:12:36.015913Z",
     "shell.execute_reply": "2021-12-28T12:12:36.015033Z",
     "shell.execute_reply.started": "2021-12-28T12:12:36.003242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_loop(model, loader, loss_func):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_dices = []\n",
    "    \n",
    "#     for i, (image, mask) in enumerate(tqdm(loader)):\n",
    "    for i, (image, mask) in enumerate(loader):\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        outputs = model(image)\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n",
    "\n",
    "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
    "        loss = loss_func(outputs, mask)\n",
    "        train_losses.append(loss.item())\n",
    "        train_dices.append(dice)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return train_dices, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:36.018254Z",
     "iopub.status.busy": "2021-12-28T12:12:36.017628Z",
     "iopub.status.idle": "2021-12-28T12:12:36.029836Z",
     "shell.execute_reply": "2021-12-28T12:12:36.029003Z",
     "shell.execute_reply.started": "2021-12-28T12:12:36.018213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval_loop(model, loader, loss_func, training=True):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_dice = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (image, mask) in enumerate(loader):\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "    \n",
    "            outputs = model(image)\n",
    "            loss = loss_func(outputs, mask)\n",
    "            \n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_dice += dice\n",
    "        \n",
    "        val_mean_dice = val_dice / step\n",
    "        val_mean_loss = val_loss / step\n",
    "        \n",
    "        if training:\n",
    "            scheduler.step(val_mean_dice)\n",
    "        \n",
    "    return val_mean_dice, val_mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:36.032026Z",
     "iopub.status.busy": "2021-12-28T12:12:36.031265Z",
     "iopub.status.idle": "2021-12-28T12:12:36.042085Z",
     "shell.execute_reply": "2021-12-28T12:12:36.041327Z",
     "shell.execute_reply.started": "2021-12-28T12:12:36.031983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n",
    "    train_loss_history = []\n",
    "    train_dice_history = []\n",
    "    val_loss_history = []\n",
    "    val_dice_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_dices, train_losses = train_loop(model, train_loader, loss_func)\n",
    "        train_mean_dice = np.array(train_dices).mean()\n",
    "        train_mean_loss = np.array(train_losses).mean()\n",
    "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func)\n",
    "        \n",
    "        train_loss_history.append(np.array(train_losses).mean())\n",
    "        train_dice_history.append(np.array(train_dices).mean())\n",
    "        val_loss_history.append(val_mean_loss)\n",
    "        val_dice_history.append(val_mean_dice)\n",
    "        \n",
    "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs,\n",
    "                                                                                                                 train_mean_loss,\n",
    "                                                                                                                 val_mean_loss,\n",
    "                                                                                                                 train_mean_dice,\n",
    "                                                                                                                 val_mean_dice))\n",
    "        \n",
    "\n",
    "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "The learning rate scheduler that we use here is **ReduceLROnPlateau** in `max` mode with `patience=3` which\n",
    "reduce the LR if quantity monitored stops increasing after 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:36.044021Z",
     "iopub.status.busy": "2021-12-28T12:12:36.043587Z",
     "iopub.status.idle": "2021-12-28T12:12:36.056725Z",
     "shell.execute_reply": "2021-12-28T12:12:36.055864Z",
     "shell.execute_reply.started": "2021-12-28T12:12:36.043982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:12:36.061405Z",
     "iopub.status.busy": "2021-12-28T12:12:36.060382Z",
     "iopub.status.idle": "2021-12-28T12:31:10.526962Z",
     "shell.execute_reply": "2021-12-28T12:31:10.525078Z",
     "shell.execute_reply.started": "2021-12-28T12:12:36.061364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(train_dl, val_dl, bce_dice_loss, optimizer, scheduler, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICE Score History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:31:10.529422Z",
     "iopub.status.busy": "2021-12-28T12:31:10.529067Z",
     "iopub.status.idle": "2021-12-28T12:31:10.768866Z",
     "shell.execute_reply": "2021-12-28T12:31:10.768076Z",
     "shell.execute_reply.started": "2021-12-28T12:31:10.529371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n",
    "    \n",
    "    x = np.arange(num_epochs)\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, train_dice_history, label='Train DICE', lw=3, c=\"b\")\n",
    "    plt.plot(x, val_dice_history, label='Validation DICE', lw=3, c=\"r\")\n",
    "\n",
    "    plt.title(f\"{model_name}\", fontsize=20)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel(\"Epoch\", fontsize=15)\n",
    "    plt.ylabel(\"DICE\", fontsize=15)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_dice_history('UNET', train_dice_history, val_dice_history, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:31:10.770529Z",
     "iopub.status.busy": "2021-12-28T12:31:10.770183Z",
     "iopub.status.idle": "2021-12-28T12:31:10.998687Z",
     "shell.execute_reply": "2021-12-28T12:31:10.997983Z",
     "shell.execute_reply.started": "2021-12-28T12:31:10.770487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_history(model_name, train_loss_history, val_loss_history, num_epochs):\n",
    "    \n",
    "    x = np.arange(num_epochs)\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, train_loss_history, label='Train Loss', lw=3, c=\"b\")\n",
    "    plt.plot(x, val_loss_history, label='Validation Loss', lw=3, c=\"r\")\n",
    "\n",
    "    plt.title(f\"{model_name}\", fontsize=20)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel(\"Epoch\", fontsize=15)\n",
    "    plt.ylabel(\"Loss\", fontsize=15)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss_history('UNET', train_loss_history, val_loss_history, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:31:11.000537Z",
     "iopub.status.busy": "2021-12-28T12:31:11.000064Z",
     "iopub.status.idle": "2021-12-28T12:31:13.897472Z",
     "shell.execute_reply": "2021-12-28T12:31:13.896576Z",
     "shell.execute_reply.started": "2021-12-28T12:31:11.000500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_dice, test_loss = eval_loop(model, test_dl, bce_dice_loss, training=False)\n",
    "print(\"Mean IoU/DICE: {:.3f}%, Loss: {:.3f}\".format((100*test_dice), test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:31:13.899609Z",
     "iopub.status.busy": "2021-12-28T12:31:13.898881Z",
     "iopub.status.idle": "2021-12-28T12:31:14.696593Z",
     "shell.execute_reply": "2021-12-28T12:31:14.695807Z",
     "shell.execute_reply.started": "2021-12-28T12:31:13.899576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(24).values[0]\n",
    "image = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\n",
    "mask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n",
    "\n",
    "# pred\n",
    "pred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\n",
    "pred = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\n",
    "pred = model(pred.to(device))\n",
    "pred = pred.detach().cpu().numpy()[0,0,:,:]\n",
    "\n",
    "pred_t = np.copy(pred)\n",
    "pred_t[np.nonzero(pred_t < 0.3)] = 0.0\n",
    "pred_t[np.nonzero(pred_t >= 0.3)] = 255.\n",
    "pred_t = pred_t.astype(\"uint8\")\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n",
    "\n",
    "ax[0, 0].imshow(image)\n",
    "ax[0, 0].set_title(\"image\")\n",
    "ax[0, 1].imshow(mask)\n",
    "ax[0, 1].set_title(\"mask\")\n",
    "ax[1, 0].imshow(pred)\n",
    "ax[1, 0].set_title(\"prediction\")\n",
    "ax[1, 1].imshow(pred_t)\n",
    "ax[1, 1].set_title(\"prediction with threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T12:31:14.698042Z",
     "iopub.status.busy": "2021-12-28T12:31:14.697689Z",
     "iopub.status.idle": "2021-12-28T12:31:14.823150Z",
     "shell.execute_reply": "2021-12-28T12:31:14.822318Z",
     "shell.execute_reply.started": "2021-12-28T12:31:14.698006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'brain-mri-unet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
